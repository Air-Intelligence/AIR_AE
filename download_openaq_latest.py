"""
OpenAQ API v3ë¡œ Bay Area ìµœì‹  PM2.5 ê´€ì¸¡ê°’ ë‹¤ìš´ë¡œë“œ

ëª©ì :
- AirNow ëŒ€ì²´ìš© ì‹¤ì‹œê°„ PM2.5 ground truth ë°ì´í„°
- Bay Area ì „ì²´ ê´€ì¸¡ì†Œì˜ ìµœì‹  PM2.5 ì¸¡ì •ê°’ ë‹¤ìš´ë¡œë“œ
- FastAPIì—ì„œ ëª¨ë¸ ì˜ˆì¸¡ê°’ê³¼ ë¹„êµ

ì¶œë ¥:
- /mnt/data/raw/OpenAQ/latest_observations.csv

ì‚¬ìš©ë²•:
    python scripts/download/download_openaq_latest.py
"""

import sys
from pathlib import Path
import requests
import pandas as pd
from datetime import datetime, timezone
from typing import List, Dict
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))
import config
import utils

logger = utils.setup_logging(__name__)

# OpenAQ API v3 ì„¤ì •
BASE_URL = "https://api.openaq.org/v3"
HEADERS = {"X-API-Key": config.OPENAQ_API_KEY}


def get_latest_measurements_bbox(bbox: Dict, parameter_id: int = 2) -> List[Dict]:
    """
    OpenAQ API v3: BBOX ë‚´ ëª¨ë“  ì„¼ì„œì˜ ìµœì‹  PM2.5 ì¸¡ì •ê°’ ì¡°íšŒ

    2ë‹¨ê³„ ì ‘ê·¼:
    1. /v3/locationsë¡œ PM2.5 ì„¼ì„œê°€ ìˆëŠ” location ëª©ë¡ ì¡°íšŒ
    2. ê° locationì˜ /latest ì—”ë“œí¬ì¸íŠ¸ë¡œ ìµœì‹  ì¸¡ì •ê°’ ì¡°íšŒ

    Args:
        bbox: Bounding box dict with keys: west, south, east, north
        parameter_id: Parameter ID (2 = PM2.5)

    Returns:
        List of measurement dicts
    """
    logger.info(f"Fetching latest PM2.5 measurements in {bbox['name']}...")

    # Step 1: Get locations with PM2.5 sensors
    locations_url = f"{BASE_URL}/locations"
    bbox_str = f"{bbox['west']},{bbox['south']},{bbox['east']},{bbox['north']}"

    params = {
        'bbox': bbox_str,
        'parameter': 'pm25',
        'limit': 100  # ì²˜ìŒ 100ê°œ locationë§Œ
    }

    try:
        response = requests.get(locations_url, headers=HEADERS, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()

        if 'results' not in data or len(data['results']) == 0:
            logger.error("No locations found in bbox")
            return []

        locations = data['results']
        logger.info(f"  Found {len(locations)} locations with PM2.5 sensors")

    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to fetch locations: {e}")
        return []

    # Step 2: Get latest measurement for each location
    all_measurements = []

    for i, loc in enumerate(locations, 1):
        location_id = loc.get('id')
        location_name = loc.get('name', 'Unknown')
        coordinates = loc.get('coordinates', {})
        lat = coordinates.get('latitude')
        lon = coordinates.get('longitude')

        if not location_id or lat is None or lon is None:
            continue

        # Call /v3/locations/{id}/latest
        latest_url = f"{BASE_URL}/locations/{location_id}/latest"

        try:
            response = requests.get(latest_url, headers=HEADERS, params={'parameter': 'pm25'}, timeout=10)
            response.raise_for_status()
            latest_data = response.json()

            if 'results' not in latest_data or len(latest_data['results']) == 0:
                continue

            # Get first PM2.5 measurement
            measurement = latest_data['results'][0]
            value = measurement.get('value')

            # datetimeì€ dict í˜•íƒœì¼ ìˆ˜ ìˆìŒ
            datetime_obj = measurement.get('datetime')
            if isinstance(datetime_obj, dict):
                datetime_str = datetime_obj.get('utc') or datetime_obj.get('local')
            else:
                datetime_str = datetime_obj

            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì¸¡ì •ê°’ êµ¬ì¡° í™•ì¸
            if i == 1:
                import json
                logger.info(f"  Sample measurement: {json.dumps(measurement, indent=2, default=str)[:500]}")

            if value is not None:  # datetime_str ì²´í¬ ì œê±° (ì—†ì–´ë„ ì €ì¥)
                all_measurements.append({
                    'location_name': location_name,
                    'lat': lat,
                    'lon': lon,
                    'pm25': value,
                    'time': datetime_str or datetime.now(timezone.utc).isoformat(),
                    'location_id': location_id,
                    'unit': measurement.get('unit', 'Âµg/mÂ³')
                })

            if i % 10 == 0:
                logger.info(f"  Progress: {i}/{len(locations)} locations processed")

            time.sleep(1.0)  # Rate limiting (increased to avoid 429)

        except Exception as e:
            logger.warning(f"  Failed to get latest for {location_name}: {e}")
            continue

    logger.info(f"âœ“ Total measurements collected: {len(all_measurements)}")
    return all_measurements


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: OpenAQ v3ë¡œ ìµœì‹  PM2.5 ê´€ì¸¡ê°’ ë‹¤ìš´ë¡œë“œ

    ì‹¤í–‰ ìˆœì„œ:
        1. Bay Area BBOX ë‚´ ëª¨ë“  PM2.5 ì„¼ì„œ ê²€ìƒ‰
        2. ê° ì„¼ì„œì˜ ìµœì‹  ì¸¡ì •ê°’ ìˆ˜ì§‘
        3. CSV íŒŒì¼ë¡œ ì €ì¥

    ì¶œë ¥:
        - /mnt/data/raw/OpenAQ/latest_observations.csv
    """
    logger.info("=" * 60)
    logger.info("OpenAQ v3 ìµœì‹  PM2.5 ê´€ì¸¡ê°’ ë‹¤ìš´ë¡œë“œ")
    logger.info("=" * 60)

    # ========================================================================
    # 1. ìµœì‹  ì¸¡ì •ê°’ ë‹¤ìš´ë¡œë“œ
    # ========================================================================
    measurements = get_latest_measurements_bbox(config.BBOX, parameter_id=2)

    if len(measurements) == 0:
        logger.error("ë‹¤ìš´ë¡œë“œëœ ì¸¡ì •ê°’ì´ ì—†ìŠµë‹ˆë‹¤")
        logger.info("ğŸ’¡ BBOXë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë” ë„“ì€ ì˜ì—­ìœ¼ë¡œ ì‹œë„í•˜ì„¸ìš”")
        sys.exit(1)

    # ========================================================================
    # 2. DataFrame ë³€í™˜
    # ========================================================================
    df = pd.DataFrame(measurements)

    # ì‹œê°„ ì»¬ëŸ¼ í™•ì¸ ë° ë³€í™˜
    # timeì´ dictì¸ ê²½ìš° (API ì‘ë‹µ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘)
    if len(df) > 0 and isinstance(df['time'].iloc[0], dict):
        logger.warning("Time column contains dict, extracting datetime string...")
        df['time'] = df['time'].apply(lambda x: x.get('datetime') if isinstance(x, dict) else x)

    df['time'] = pd.to_datetime(df['time'])
    df['time'] = utils.to_utc_naive(df['time'])

    # ì¤‘ë³µ ì œê±° (ê°™ì€ ê´€ì¸¡ì†Œì˜ ì—¬ëŸ¬ ì„¼ì„œ)
    df = df.sort_values('time', ascending=False).groupby(['lat', 'lon', 'location_name']).first().reset_index()

    logger.info(f"âœ“ Unique stations after deduplication: {len(df)}")

    # ========================================================================
    # 3. CSV ì €ì¥
    # ========================================================================
    output_dir = Path("/mnt/data/raw/OpenAQ")
    output_dir.mkdir(parents=True, exist_ok=True)

    output_path = output_dir / "latest_observations.csv"
    df.to_csv(output_path, index=False)

    logger.info(f"\nâœ“ ì €ì¥ ì™„ë£Œ: {output_path}")

    # ========================================================================
    # 4. ìš”ì•½
    # ========================================================================
    logger.info("\n" + "=" * 60)
    logger.info("ë‹¤ìš´ë¡œë“œ ìš”ì•½:")
    logger.info("=" * 60)
    logger.info(f"  ë‹¤ìš´ë¡œë“œ ì‹œê°„:  {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} UTC")
    logger.info(f"  ê´€ì¸¡ì†Œ ìˆ˜:      {len(df)}")
    logger.info(f"  PM2.5 í‰ê· :     {df['pm25'].mean():.1f} Âµg/mÂ³")
    logger.info(f"  PM2.5 ë²”ìœ„:     [{df['pm25'].min():.1f}, {df['pm25'].max():.1f}] Âµg/mÂ³")
    logger.info(f"  ìµœì‹  ì‹œê°„:      {df['time'].max()}")
    logger.info(f"  ì¶œë ¥ íŒŒì¼:      {output_path}")
    logger.info("=" * 60)

    # ê´€ì¸¡ì†Œ ëª©ë¡ ì¶œë ¥
    logger.info("\nê´€ì¸¡ì†Œ ëª©ë¡:")
    for _, row in df.iterrows():
        logger.info(f"  - {row['location_name']}: {row['pm25']:.1f} Âµg/mÂ³ ({row['time']})")

    logger.info("\në‹¤ìŒ ë‹¨ê³„:")
    logger.info("  - FastAPIì—ì„œ ì´ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì‹¤ì‹œê°„ ë¹„êµ ì œê³µ")
    logger.info("  - ì£¼ê¸°ì ìœ¼ë¡œ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë°ì´í„° ìœ ì§€")


if __name__ == "__main__":
    main()
