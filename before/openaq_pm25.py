#!/usr/bin/env python3
"""
OpenAQ PM2.5 Label Collection & Matching
========================================
TEMPO ë°ì´í„°ì™€ ì¡°ì¸í•˜ê¸° ìœ„í•œ OpenAQ ì§€ìƒ PM2.5 ì¸¡ì •ê°’ ìˆ˜ì§‘

ì¶œë ¥: merged_with_pm25.parquet
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path

# ============================================================================
# CONFIGURATION
# ============================================================================

CONFIG = {
    # ì‹œê°„ ë²”ìœ„ (TEMPO ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•˜ê²Œ)
    'DATE_RANGE': ('2023-08-01', '2023-10-31'),

    # ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ìš” ë„ì‹œ ë˜ëŠ” ì „ì²´ ì£¼
    'LOCATIONS': {
        'state': 'CA',  # ìº˜ë¦¬í¬ë‹ˆì•„ ì „ì²´
        # ë˜ëŠ” ì£¼ìš” ë„ì‹œë§Œ:
        # 'cities': ['Los Angeles', 'San Francisco', 'San Diego', 'Sacramento', 'Fresno']
    },

    # OpenAQ API íŒŒë¼ë¯¸í„°
    'PARAMETER': 'pm25',  # PM2.5

    # TEMPO ê²©ì íŒŒì¼ ê²½ë¡œ (ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì¶œë ¥)
    'TEMPO_FILE': './tempo_l3_bayarea_202308-202310/tempo_l3_ca_merged.parquet',

    # ì¶œë ¥ ê²½ë¡œ
    'OUTPUT_FILE': './tempo_l3_bayarea_202308-202310/merged_with_pm25.parquet',

    # ìµœê·¼ì ‘ ë§¤ì¹­ ê±°ë¦¬ ì„ê³„ê°’ (km)
    'MAX_DISTANCE_KM': 50,
}


# ============================================================================
# OpenAQ API Functions
# ============================================================================

def fetch_openaq_pm25(date_start, date_end, state='CA'):
    """
    OpenAQ API v2ë¡œ PM2.5 ë°ì´í„° ìˆ˜ì§‘

    API ë¬¸ì„œ: https://docs.openaq.org/
    """
    print(f"ğŸŒ OpenAQ PM2.5 ìˆ˜ì§‘ ì¤‘...")
    print(f"   ì§€ì—­: {state}")
    print(f"   ê¸°ê°„: {date_start} ~ {date_end}\n")

    base_url = "https://api.openaq.org/v2/measurements"

    all_data = []
    page = 1
    limit = 10000  # API ìµœëŒ€

    while True:
        params = {
            'parameter': 'pm25',
            'country': 'US',
            'location': state,  # ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼
            'date_from': date_start,
            'date_to': date_end,
            'limit': limit,
            'page': page,
        }

        try:
            print(f"   í˜ì´ì§€ {page} ìš”ì²­ ì¤‘...", end=' ')
            response = requests.get(base_url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()
            results = data.get('results', [])

            if not results:
                print("ì™„ë£Œ")
                break

            all_data.extend(results)
            print(f"{len(results)}ê°œ ìˆ˜ì§‘")

            # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
            meta = data.get('meta', {})
            if meta.get('found', 0) <= page * limit:
                break

            page += 1

        except Exception as e:
            print(f"\nâš ï¸  API ì˜¤ë¥˜: {e}")
            break

    print(f"\nâœ… ì´ {len(all_data):,}ê°œ ì¸¡ì •ê°’ ìˆ˜ì§‘\n")
    return all_data


def parse_openaq_data(raw_data):
    """OpenAQ JSON â†’ pandas DataFrame"""
    if not raw_data:
        return pd.DataFrame()

    records = []

    for item in raw_data:
        try:
            records.append({
                'time': pd.to_datetime(item['date']['utc']),
                'pm25': item['value'],
                'lat': item['coordinates']['latitude'],
                'lon': item['coordinates']['longitude'],
                'location': item['location'],
                'city': item.get('city', ''),
                'unit': item['unit'],
            })
        except (KeyError, TypeError):
            continue

    df = pd.DataFrame(records)

    # ê¸°ë³¸ QC
    df = df[df['pm25'] >= 0]  # ìŒìˆ˜ ì œê±°
    df = df[df['pm25'] < 1000]  # ì´ìƒì¹˜ ì œê±°

    # ì‹œê°„ ì •ë ¬
    df = df.sort_values('time').reset_index(drop=True)

    print(f"ğŸ“Š íŒŒì‹± ì™„ë£Œ: {len(df):,}í–‰")
    print(f"   ì‹œê°„ ë²”ìœ„: {df['time'].min()} ~ {df['time'].max()}")
    print(f"   ì¸¡ì •ì†Œ ìˆ˜: {df['location'].nunique()}ê°œ")
    print(f"   PM2.5 ë²”ìœ„: {df['pm25'].min():.1f} ~ {df['pm25'].max():.1f} Âµg/mÂ³\n")

    return df


# ============================================================================
# Spatial Matching (TEMPO â†” OpenAQ)
# ============================================================================

def haversine_distance(lat1, lon1, lat2, lon2):
    """ìœ„ê²½ë„ ê°„ ê±°ë¦¬ ê³„ì‚° (km)"""
    R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)

    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))

    return R * c


def match_nearest_grid(tempo_df, openaq_df, max_distance_km=50):
    """
    OpenAQ ì¸¡ì •ì†Œë¥¼ TEMPO ê²©ìì— ìµœê·¼ì ‘ ë§¤ì¹­

    ë°©ë²•:
    1. ê° OpenAQ ì¸¡ì •ì†Œì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ TEMPO ê²©ì ì°¾ê¸°
    2. ì‹œê°„ë³„ë¡œ ì¡°ì¸
    """
    print("ğŸ”— TEMPO â†” OpenAQ ê³µê°„ ë§¤ì¹­ ì¤‘...")

    # TEMPO ê³ ìœ  ê²©ìì 
    tempo_grids = tempo_df[['lat', 'lon']].drop_duplicates()
    print(f"   TEMPO ê²©ì: {len(tempo_grids):,}ê°œ")

    # OpenAQ ê³ ìœ  ì¸¡ì •ì†Œ
    openaq_stations = openaq_df[['lat', 'lon', 'location']].drop_duplicates()
    print(f"   OpenAQ ì¸¡ì •ì†Œ: {len(openaq_stations):,}ê°œ\n")

    # ê° ì¸¡ì •ì†Œì— ëŒ€í•´ ìµœê·¼ì ‘ ê²©ì ì°¾ê¸°
    matches = []

    for idx, station in openaq_stations.iterrows():
        s_lat, s_lon = station['lat'], station['lon']

        # ëª¨ë“  TEMPO ê²©ìì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        distances = haversine_distance(
            s_lat, s_lon,
            tempo_grids['lat'].values,
            tempo_grids['lon'].values
        )

        min_dist_idx = np.argmin(distances)
        min_dist = distances[min_dist_idx]

        if min_dist <= max_distance_km:
            tempo_grid = tempo_grids.iloc[min_dist_idx]

            matches.append({
                'openaq_location': station['location'],
                'openaq_lat': s_lat,
                'openaq_lon': s_lon,
                'tempo_lat': tempo_grid['lat'],
                'tempo_lon': tempo_grid['lon'],
                'distance_km': min_dist,
            })

        if (idx + 1) % 50 == 0:
            print(f"   ì§„í–‰: {idx+1}/{len(openaq_stations)}...")

    match_df = pd.DataFrame(matches)

    print(f"\nâœ… ë§¤ì¹­ ì™„ë£Œ: {len(match_df)}ê°œ ì¸¡ì •ì†Œ")
    print(f"   í‰ê·  ê±°ë¦¬: {match_df['distance_km'].mean():.1f} km")
    print(f"   ìµœëŒ€ ê±°ë¦¬: {match_df['distance_km'].max():.1f} km\n")

    return match_df


def merge_tempo_openaq(tempo_df, openaq_df, match_df, time_tolerance='1H'):
    """
    ì‹œê³µê°„ ì¡°ì¸

    ì „ëµ:
    1. ê³µê°„: match_df ì‚¬ìš©
    2. ì‹œê°„: merge_asof (ìµœê·¼ì ‘ ì‹œê°„ ë§¤ì¹­)
    """
    print("ğŸ”€ TEMPO + OpenAQ ì‹œê³µê°„ ì¡°ì¸ ì¤‘...\n")

    # OpenAQì— TEMPO ê²©ì ì¢Œí‘œ ì¶”ê°€
    openaq_mapped = openaq_df.merge(
        match_df[['openaq_location', 'tempo_lat', 'tempo_lon']],
        left_on='location',
        right_on='openaq_location',
        how='inner'
    )

    print(f"   OpenAQ (ê²©ì ë§¤í•‘ í›„): {len(openaq_mapped):,}í–‰")

    # ì‹œê°„ ì •ë ¬ (merge_asof ìš”êµ¬ì‚¬í•­)
    tempo_df = tempo_df.sort_values('time')
    openaq_mapped = openaq_mapped.sort_values('time')

    # ê²©ìë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¡°ì¸
    merged_list = []

    for (lat, lon), group in openaq_mapped.groupby(['tempo_lat', 'tempo_lon']):
        # í•´ë‹¹ ê²©ìì˜ TEMPO ë°ì´í„°
        tempo_grid = tempo_df[
            (tempo_df['lat'] == lat) &
            (tempo_df['lon'] == lon)
        ].copy()

        if tempo_grid.empty:
            continue

        # ìµœê·¼ì ‘ ì‹œê°„ ì¡°ì¸
        merged_grid = pd.merge_asof(
            tempo_grid,
            group[['time', 'pm25', 'location']],
            on='time',
            tolerance=pd.Timedelta(time_tolerance),
            direction='nearest'
        )

        merged_list.append(merged_grid)

    if not merged_list:
        print("âš ï¸  ì¡°ì¸ ê²°ê³¼ ì—†ìŒ\n")
        return pd.DataFrame()

    merged_all = pd.concat(merged_list, ignore_index=True)

    # PM2.5 ì¸¡ì •ê°’ ìˆëŠ” í–‰ë§Œ ìœ ì§€
    merged_all = merged_all.dropna(subset=['pm25'])

    print(f"âœ… ìµœì¢… ë³‘í•©: {len(merged_all):,}í–‰")
    print(f"   PM2.5 ì¸¡ì •ì†Œ: {merged_all['location'].nunique()}ê°œ")
    print(f"   ì‹œê°„ ë²”ìœ„: {merged_all['time'].min()} ~ {merged_all['time'].max()}\n")

    return merged_all


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("="*70)
    print("  OpenAQ PM2.5 + TEMPO Merge Pipeline")
    print("="*70)
    print()

    # 1. OpenAQ ë°ì´í„° ìˆ˜ì§‘
    raw_data = fetch_openaq_pm25(
        CONFIG['DATE_RANGE'][0],
        CONFIG['DATE_RANGE'][1],
        CONFIG['LOCATIONS']['state']
    )

    openaq_df = parse_openaq_data(raw_data)

    if openaq_df.empty:
        print("âŒ OpenAQ ë°ì´í„° ì—†ìŒ. ì¢…ë£Œ.\n")
        return

    # 2. TEMPO ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ TEMPO ë°ì´í„° ë¡œë”©: {CONFIG['TEMPO_FILE']}\n")

    if not Path(CONFIG['TEMPO_FILE']).exists():
        print(f"âŒ TEMPO íŒŒì¼ ì—†ìŒ: {CONFIG['TEMPO_FILE']}")
        print("   â†’ ë¨¼ì € tempo_ca_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n")
        return

    tempo_df = pd.read_parquet(CONFIG['TEMPO_FILE'])
    print(f"âœ… TEMPO: {len(tempo_df):,}í–‰ Ã— {len(tempo_df.columns)}ì—´\n")

    # 3. ê³µê°„ ë§¤ì¹­
    match_df = match_nearest_grid(
        tempo_df,
        openaq_df,
        CONFIG['MAX_DISTANCE_KM']
    )

    if match_df.empty:
        print("âŒ ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ. ì¢…ë£Œ.\n")
        return

    # 4. ì‹œê³µê°„ ë³‘í•©
    merged_df = merge_tempo_openaq(
        tempo_df,
        openaq_df,
        match_df
    )

    if merged_df.empty:
        print("âŒ ë³‘í•© ì‹¤íŒ¨. ì¢…ë£Œ.\n")
        return

    # 5. ì €ì¥
    out_path = Path(CONFIG['OUTPUT_FILE'])
    out_path.parent.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ’¾ ì €ì¥ ì¤‘: {out_path}\n")
    merged_df.to_parquet(out_path, compression='snappy', index=False)

    size_mb = out_path.stat().st_size / 1024 / 1024
    print(f"âœ… ì™„ë£Œ! ({size_mb:.1f} MB)\n")

    # 6. ìš”ì•½
    print("="*70)
    print("  ë°ì´í„° ìš”ì•½")
    print("="*70)
    print(merged_df.info())
    print()
    print("ğŸ“Š PM2.5 í†µê³„:")
    print(merged_df['pm25'].describe())
    print()
    print("ğŸ“‹ ìƒ˜í”Œ:")
    print(merged_df.head(10))


if __name__ == '__main__':
    main()
