"""
TEMPO O3 Standard V04 ì •ì  ë°ì´í„° ë‹¤ìš´ë¡œë“œ

ëª©ì :
- TEMPO O3 NRTê°€ ì—†ìœ¼ë¯€ë¡œ Standard V04 ê³¼ê±° ë°ì´í„°ë¥¼ ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©
- í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¥¸ ê¸°ê°„ì˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœê·¼ 3ì¼)
- FastAPIì—ì„œ NO2 NRTì™€ ì¡°í•©í•˜ì—¬ ì œê³µ

ì¶œë ¥:
- /mnt/data/features/tempo/o3_static/*.nc (NetCDF)
- /mnt/data/features/tempo/o3_static.parquet (ì „ì²˜ë¦¬ í›„)

ì‚¬ìš©ë²•:
    python download_o3_static.py
"""

from __future__ import annotations

import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List

import earthaccess
import xarray as xr
import pandas as pd
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))
import config
import utils

logger = utils.setup_logging(__name__)


def auth_via_netrc() -> None:
    """
    Earthdata ì¸ì¦ (~/.netrc ì‚¬ìš©)
    """
    earthaccess.login(strategy="netrc")
    logger.info("âœ“ Earthdata authenticated via ~/.netrc")


def bbox_tuple(bbox: dict) -> tuple[float, float, float, float]:
    """BBOX ë”•ì…”ë„ˆë¦¬ â†’ íŠœí”Œ ë³€í™˜"""
    return (bbox["west"], bbox["south"], bbox["east"], bbox["north"])


def search_o3_granules(start: datetime, end: datetime, bbox: dict) -> List:
    """
    TEMPO O3 Standard V04 granule ê²€ìƒ‰

    Args:
        start: ê²€ìƒ‰ ì‹œì‘ ì‹œê°„ (UTC)
        end: ê²€ìƒ‰ ì¢…ë£Œ ì‹œê°„ (UTC)
        bbox: ê²€ìƒ‰ ì˜ì—­ (Bay Area)

    Returns:
        ê²€ìƒ‰ëœ granule ë¦¬ìŠ¤íŠ¸
    """
    bt = bbox_tuple(bbox)

    # NASA CMRì—ì„œ TEMPO O3 Standard V04 ê²€ìƒ‰
    results = earthaccess.search_data(
        short_name="TEMPO_O3TOT_L3",
        version="V04",  # Standard V04
        temporal=(start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d")),
        bounding_box=bt,
        cloud_hosted=True,
    )

    logger.info(
        f"TEMPO O3 V04: found {len(results)} granules "
        f"({start.date()} ~ {end.date()})"
    )
    return results


def download_granules(granules: List, outdir: Path, threads: int = 12) -> list[str]:
    """
    Granule ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ

    Args:
        granules: ê²€ìƒ‰ëœ granule ë¦¬ìŠ¤íŠ¸
        outdir: ë‹¤ìš´ë¡œë“œ ì¶œë ¥ ë””ë ‰í„°ë¦¬
        threads: ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ìŠ¤ë ˆë“œ ìˆ˜

    Returns:
        ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if not granules:
        logger.warning("No granules to download")
        return []

    outdir.mkdir(parents=True, exist_ok=True)

    files = earthaccess.download(granules, str(outdir), threads=threads) or []

    ok = []
    for f in files:
        p = Path(f)
        if p.exists() and p.stat().st_size > 0:
            ok.append(str(p))

    if ok:
        sample = ", ".join(Path(f).name for f in ok[:3])
        logger.info(f"âœ“ Downloaded {len(ok)} files â†’ {outdir} (sample: {sample}...)")
    else:
        logger.warning("No files downloaded")

    return ok


def process_o3_netcdf(nc_files: List[str]) -> pd.DataFrame:
    """
    TEMPO O3 NetCDF íŒŒì¼ì„ Parquetìœ¼ë¡œ ì „ì²˜ë¦¬

    Args:
        nc_files: NetCDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    Returns:
        Tidy DataFrame (time, lat, lon, o3)
    """
    logger.info(f"\nO3 NetCDF ì „ì²˜ë¦¬ ì¤‘... ({len(nc_files)}ê°œ íŒŒì¼)")

    all_dfs = []

    for i, file in enumerate(nc_files, 1):
        try:
            # V04ëŠ” /product/ ê·¸ë£¹ì— ë°ì´í„° ìˆìŒ
            # 1. ë£¨íŠ¸ì—ì„œ ì¢Œí‘œ ì½ê¸°
            with xr.open_dataset(file, chunks="auto") as ds_root:
                coords_dict = {
                    'longitude': ds_root['longitude'],
                    'latitude': ds_root['latitude'],
                    'time': ds_root['time']
                }

            # 2. /product/ ê·¸ë£¹ì—ì„œ ë°ì´í„° ì½ê¸°
            with xr.open_dataset(file, group='/product', chunks="auto") as ds:
                ds = ds.assign_coords(coords_dict)

                # Bay Areaë¡œ ì„œë¸Œì…‹íŒ…
                ds = utils.subset_bbox(ds)

                # ë³€ìˆ˜ëª… í‘œì¤€í™”: column_amount_o3 â†’ o3
                if 'column_amount_o3' in ds:
                    ds = ds.rename({'column_amount_o3': 'o3'})
                elif 'vertical_column_total' in ds:
                    ds = ds.rename({'vertical_column_total': 'o3'})

                # Tidy format ë³€í™˜
                df = utils.netcdf_to_tidy(ds, var_mapping=None)

            all_dfs.append(df)

            if i % 10 == 0 or i == len(nc_files):
                logger.info(f"  {i}/{len(nc_files)} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({Path(file).name}): {e}")
            continue

    if len(all_dfs) == 0:
        logger.error("ì¶”ì¶œëœ ë°ì´í„° ì—†ìŒ")
        return pd.DataFrame()

    # ëª¨ë“  DataFrame í•©ì¹˜ê¸°
    df = pd.concat(all_dfs, ignore_index=True)

    # UTC ì‹œê°„ ì •ê·œí™”
    df["time"] = utils.to_utc_naive(df["time"])

    # ì¤‘ë³µ ì œê±°
    df = utils.dedup_grid(df)

    logger.info(f"âœ“ O3 ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df):,} í–‰")

    return df


def main() -> None:
    """
    ë©”ì¸ í•¨ìˆ˜: TEMPO O3 Standard V04 ì •ì  ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬

    ì‹¤í–‰ ìˆœì„œ:
        1. ìµœê·¼ 2ì£¼ ê¸°ê°„ì˜ TEMPO O3 Standard V04 ë°ì´í„° ê²€ìƒ‰
        2. NetCDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        3. ì „ì²˜ë¦¬ í›„ Parquet ì €ì¥

    ì¶œë ¥:
        - /mnt/data/features/tempo/o3_static/*.nc
        - /mnt/data/features/tempo/o3_static.parquet
    """
    logger.info("=" * 60)
    logger.info("TEMPO O3 Standard V04 ì •ì  ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    logger.info("=" * 60)

    # ========================================================================
    # ì‹œê°„ ë²”ìœ„ ì„¤ì •: ìµœê·¼ 3ì¼ (Standard V04ëŠ” ë©°ì¹  ì§€ì—°ë¨)
    # ========================================================================
    utc_now = datetime.now(timezone.utc)
    # Standard V04ëŠ” ë³´í†µ 1ì£¼ì¼ ì •ë„ ì§€ì—°ë˜ë¯€ë¡œ, 1~2ì£¼ ì „ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    start = (utc_now - timedelta(days=10)).replace(tzinfo=None)
    end = (utc_now - timedelta(days=7)).replace(tzinfo=None)

    logger.info(f"Period (UTC): {start.date()} ~ {end.date()} (3ì¼)")
    logger.info(f"Region: {config.BBOX.get('name', 'Bay Area')}")
    logger.info("âš ï¸  Standard V04ëŠ” ì‹¤ì‹œê°„ì´ ì•„ë‹Œ ê³¼ê±° ë°ì´í„°ì…ë‹ˆë‹¤")

    # ========================================================================
    # 1. TEMPO O3 Standard V04 ë‹¤ìš´ë¡œë“œ
    # ========================================================================
    logger.info("\n[1/2] TEMPO O3 V04 ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ...")

    try:
        # NASA Earthdata ì¸ì¦
        auth_via_netrc()

        # O3 granule ê²€ìƒ‰
        o3_granules = search_o3_granules(start, end, config.BBOX)

        if not o3_granules:
            logger.error("ê²€ìƒ‰ëœ O3 granuleì´ ì—†ìŠµë‹ˆë‹¤")
            logger.info("ğŸ’¡ ë” ì´ì „ ê¸°ê°„ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš” (Standard V04ëŠ” ì§€ì—°ë¨)")
            sys.exit(1)

        # ë‹¤ìš´ë¡œë“œ
        out_dir = Path("/mnt/data/features/tempo/o3_static")
        o3_files = download_granules(o3_granules, out_dir, threads=12)

        if not o3_files:
            logger.error("ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            sys.exit(1)

        logger.info(f"âœ“ O3 ë‹¤ìš´ë¡œë“œ: {len(o3_files)} files â†’ {out_dir}")

    except Exception as e:
        logger.error(f"O3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        sys.exit(1)

    # ========================================================================
    # 2. NetCDF â†’ Parquet ì „ì²˜ë¦¬
    # ========================================================================
    logger.info("\n[2/2] O3 ì „ì²˜ë¦¬ (NetCDF â†’ Parquet)...")

    try:
        df_o3 = process_o3_netcdf(o3_files)

        if df_o3.empty:
            logger.error("ì „ì²˜ë¦¬ í›„ ë°ì´í„° ì—†ìŒ")
            sys.exit(1)

        # QC ì ìš©
        logger.info("QC ì ìš© ì¤‘...")
        df_o3 = utils.apply_qc(df_o3)

        # O3 ê²°ì¸¡ì¹˜ ì œê±°
        df_o3 = df_o3.dropna(subset=["o3"])

        logger.info(f"âœ“ QC í›„: {len(df_o3):,} í–‰")

        # Parquet ì €ì¥
        output_path = Path("/mnt/data/features/tempo/o3_static.parquet")
        output_path.parent.mkdir(parents=True, exist_ok=True)

        utils.save_parquet(df_o3, output_path, downcast=True)

        logger.info(f"âœ“ Parquet ì €ì¥: {output_path}")

    except Exception as e:
        logger.error(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        sys.exit(1)

    # ========================================================================
    # ì™„ë£Œ ë©”ì‹œì§€
    # ========================================================================
    logger.info("\n" + "=" * 60)
    logger.info("âœ“ O3 ì •ì  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    logger.info("=" * 60)
    logger.info(f"  ì‹œê°„ ë²”ìœ„:      {df_o3['time'].min()} ~ {df_o3['time'].max()}")
    logger.info(f"  ì´ ë°ì´í„° í–‰:   {len(df_o3):,}")
    logger.info(f"  ê³ ìœ  ì‹œê°„ëŒ€:    {df_o3['time'].nunique():,}")
    logger.info(f"  ê³ ìœ  ìœ„ì¹˜:      {len(df_o3[['lat','lon']].drop_duplicates()):,}")
    logger.info(f"  ì¶œë ¥ íŒŒì¼:      {output_path}")
    logger.info(f"  íŒŒì¼ í¬ê¸°:      {output_path.stat().st_size / 1024**2:.1f} MB")
    logger.info("=" * 60)
    logger.info("\në‹¤ìŒ ë‹¨ê³„:")
    logger.info("  1. FastAPI ìˆ˜ì • (O3 ì •ì  ë°ì´í„° ë¡œë”©)")
    logger.info("  2. API ì„œë²„ ì‹¤í–‰ (python open_aq.py)")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
